import torch  
import torchvision
import os
import json
import cv2
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, Dataset
from torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.transforms import functional as F
from sklearn.metrics import classification_report
from collections import defaultdict
from datetime import datetime
import pytz
from PIL import Image

# =============================
# 1. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –∏ –æ–±—É—á–µ–Ω–∏—è
# =============================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
BATCH_SIZE = 4
EPOCHS = 50
LEARNING_RATE = 0.0005
DATASET_PATH = r"E:/MAI/NIR/Faster_R-CNN/dataset/"
MODEL_PATH = "faster_rcnn.pth"

# =============================
# 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Ç–∏ –∫ dataset
# =============================
if not os.path.exists(DATASET_PATH):
    raise FileNotFoundError(f"‚ùå –û—à–∏–±–∫–∞: –ü–∞–ø–∫–∞ {DATASET_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")

# =============================
# 3. –ö–∞—Å—Ç–æ–º–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç COCO
# =============================
class CustomDataset(Dataset):
    def __init__(self, root, split="train"):
        self.root = os.path.join(root, split)
        ann_file = os.path.join(self.root, "_annotations.coco.json")

        if not os.path.exists(ann_file):
            raise FileNotFoundError(f"‚ùå –§–∞–π–ª –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π {ann_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")

        with open(ann_file, "r") as f:
            self.coco_data = json.load(f)

        self.class_names = {cat["id"]: cat["name"] for cat in self.coco_data["categories"]}
        self.image_info = {img["id"]: img["file_name"] for img in self.coco_data["images"]}
        self.annotations = defaultdict(list)

        for ann in self.coco_data["annotations"]:
            self.annotations[ann["image_id"]].append(ann)

    def __getitem__(self, idx):
        img_name = self.image_info[idx]
        img_path = os.path.join(self.root, img_name)

        img = F.to_tensor(Image.open(img_path).convert("RGB"))
        anns = self.annotations[idx]

        boxes = torch.tensor([ann["bbox"] for ann in anns], dtype=torch.float32) if anns else torch.zeros((0, 4))
        labels = torch.tensor([ann["category_id"] for ann in anns], dtype=torch.int64) if anns else torch.zeros((0,), dtype=torch.int64)

        if len(boxes) > 0:
            boxes[:, 2] += boxes[:, 0]  # x_max = x_min + width
            boxes[:, 3] += boxes[:, 1]  # y_max = y_min + height

        return img, {"boxes": boxes, "labels": labels}

    def __len__(self):
        return len(self.image_info)

# =============================
# 4. –û—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ (Windows Fix)
# =============================
if __name__ == '__main__':
    train_dataset = CustomDataset(DATASET_PATH, split="train")
    test_dataset = CustomDataset(DATASET_PATH, split="test")

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, collate_fn=lambda batch: tuple(zip(*batch)))
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=lambda batch: tuple(zip(*batch)))

    # =============================
    # 5. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª—å Faster R-CNN
    # =============================
    def get_faster_rcnn_model(num_classes):
        weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT
        model = fasterrcnn_resnet50_fpn(weights=weights)
        in_features = model.roi_heads.box_predictor.cls_score.in_features
        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
        return model

    num_classes = len(train_dataset.class_names) + 1
    model = get_faster_rcnn_model(num_classes).to(DEVICE)

    # =============================
    # 6. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    # =============================
    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

    print("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")

    for epoch in range(EPOCHS):
        model.train()
        total_loss = 0
        moscow_time = datetime.now(pytz.timezone('Europe/Moscow')).strftime("%H:%M:%S")
        print(f"üî• –ù–∞—á–∞–ª–æ —ç–ø–æ—Ö–∏ {epoch+1}/{EPOCHS} | –í—Ä–µ–º—è (–ú–æ—Å–∫–≤–∞): {moscow_time}")

        for imgs, targets in train_loader:
            imgs = list(img.to(DEVICE) for img in imgs)
            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]

            optimizer.zero_grad()
            loss_dict = model(imgs, targets)
            loss = sum(loss for loss in loss_dict.values())

            if torch.isnan(loss):
                print(f"‚ö†Ô∏è Loss NaN –≤ —ç–ø–æ—Ö–µ {epoch+1}")
                break

            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        lr_scheduler.step()
        print(f"‚úÖ –≠–ø–æ—Ö–∞ {epoch+1} –∑–∞–≤–µ—Ä—à–µ–Ω–∞. | –í—Ä–µ–º—è (–ú–æ—Å–∫–≤–∞): {moscow_time} | Loss: {total_loss:.4f}")

    torch.save(model.state_dict(), MODEL_PATH)
    print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")

    # =============================
    # 7. –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
    # =============================
    def load_faster_rcnn_model(num_classes, model_path):
        model = fasterrcnn_resnet50_fpn(weights=None)
        in_features = model.roi_heads.box_predictor.cls_score.in_features
        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
        model.load_state_dict(torch.load(model_path, map_location=DEVICE))
        model.to(DEVICE)
        model.eval()
        return model

    def evaluate_model(model, test_loader, class_names):
        all_preds = []
        all_targets = []

        with torch.no_grad():
            for imgs, targets in test_loader:
                imgs = list(img.to(DEVICE) for img in imgs)
                predictions = model(imgs)

                for pred, target in zip(predictions, targets):
                    pred_labels = pred["labels"].cpu().numpy().tolist()
                    target_labels = target["labels"].cpu().numpy().tolist()

                    max_len = max(len(pred_labels), len(target_labels))
                    pred_labels += [0] * (max_len - len(pred_labels))
                    target_labels += [0] * (max_len - len(target_labels))

                    all_preds.extend(pred_labels)
                    all_targets.extend(target_labels)

        if len(all_preds) == 0 or len(all_targets) == 0:
            print("‚ö†Ô∏è –ù–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏–ª–∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.")
            return

        print("\nüìä **–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –∫–ª–∞—Å—Å—É:**")
        print(classification_report(
            all_targets, all_preds, labels=sorted(test_dataset.class_names.keys()), target_names=list(test_dataset.class_names.values()), zero_division=1
        ))

    print("üîç –ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏...")
    model = load_faster_rcnn_model(num_classes, MODEL_PATH)
    evaluate_model(model, test_loader, test_dataset.class_names)
